import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.optimize import curve_fit
import plotly.graph_objects as go
import plotly.express as px

# Configuration de la page
st.set_page_config(
    page_title="Zipf Mineral Discovery Application",
    page_icon="‚õèÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© pour le pied de page et centrage
st.markdown("""
    <style>
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        background-color: #f0f2f6;
        color: #262730;
        text-align: center;
        padding: 10px;
        font-size: 14px;
        border-top: 1px solid #e0e0e0;
        z-index: 999;
    }
    .main {
        margin-bottom: 60px;
    }
    h1, h2, h3 {
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

# En-t√™te principal
st.title("‚õèÔ∏è Zipf Mineral Discovery Application")
st.markdown("### Test de Kolmogorov-Smirnov et pr√©dictions des gisements non d√©couverts dans une province aurif√®re")
st.markdown("<p style='text-align: center;'><strong>Auteurs: Didier Ouedraogo, PGeo | Koulou Danshoko, Geo</strong></p>", unsafe_allow_html=True)
st.divider()

# Sidebar pour les param√®tres
with st.sidebar:
    st.header("üìä Param√®tres de l'analyse")
    
    # Options de chargement des donn√©es
    data_source = st.radio(
        "Source des donn√©es",
        ["Donn√©es d'exemple", "Charger un fichier"]
    )
    
    uploaded_file = None
    if data_source == "Charger un fichier":
        uploaded_file = st.file_uploader(
            "Charger un fichier CSV ou Excel",
            type=["csv", "xlsx", "xls"]
        )
    
    st.divider()
    
    # Param√®tres de l'analyse
    confidence_level = st.slider(
        "Niveau de confiance (%)",
        min_value=90,
        max_value=99,
        value=95,
        step=1
    )
    
    alpha = 1 - (confidence_level / 100)
    
    st.divider()
    st.info("üí° L'analyse de Zipf permet d'estimer le nombre de gisements non encore d√©couverts dans une province mini√®re.")

# Fonction pour g√©n√©rer des donn√©es d'exemple
def generate_example_data():
    np.random.seed(42)
    n_deposits = 25
    tonnages = np.sort(np.random.lognormal(mean=5, sigma=1.5, size=n_deposits))[::-1]
    
    data = pd.DataFrame({
        'Rang': range(1, n_deposits + 1),
        'Tonnage (Mt)': tonnages,
        'Nom_Gisement': [f'Gisement_{i}' for i in range(1, n_deposits + 1)]
    })
    return data

# Chargement des donn√©es
df = None
if data_source == "Donn√©es d'exemple":
    df = generate_example_data()
    st.success("‚úÖ Donn√©es d'exemple charg√©es avec succ√®s!")
else:
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            st.success(f"‚úÖ Fichier '{uploaded_file.name}' charg√© avec succ√®s!")
        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement du fichier: {e}")
            st.stop()
    else:
        st.warning("‚ö†Ô∏è Veuillez charger un fichier pour continuer.")
        st.stop()

# V√©rification des colonnes requises
if df is not None:
    required_columns = ['Tonnage (Mt)']
    if not all(col in df.columns for col in required_columns):
        st.error(f"‚ùå Le fichier doit contenir au minimum la colonne: {required_columns}")
        st.info("Colonnes disponibles: " + ", ".join(df.columns.tolist()))
        st.stop()

# Validation et pr√©paration des donn√©es
st.header("üìã Aper√ßu des donn√©es")

col1, col2, col3 = st.columns(3)
with col1:
    st.metric("Nombre de gisements", len(df))
with col2:
    st.metric("Tonnage total (Mt)", f"{df['Tonnage (Mt)'].sum():.2f}")
with col3:
    st.metric("Tonnage moyen (Mt)", f"{df['Tonnage (Mt)'].mean():.2f}")

st.dataframe(df, use_container_width=True)

# Tri des donn√©es par tonnage d√©croissant
df_sorted = df.sort_values('Tonnage (Mt)', ascending=False).reset_index(drop=True)
df_sorted['Rang'] = range(1, len(df_sorted) + 1)

# Analyse de Zipf
st.header("üìà Analyse de Zipf")

# Transformation logarithmique
df_sorted['log_Rang'] = np.log(df_sorted['Rang'])
df_sorted['log_Tonnage'] = np.log(df_sorted['Tonnage (Mt)'])

# R√©gression lin√©aire
slope, intercept, r_value, p_value, std_err = stats.linregress(
    df_sorted['log_Rang'], 
    df_sorted['log_Tonnage']
)

# Pr√©dictions
df_sorted['log_Tonnage_pred'] = slope * df_sorted['log_Rang'] + intercept
df_sorted['Tonnage_pred'] = np.exp(df_sorted['log_Tonnage_pred'])

# Affichage des r√©sultats de r√©gression
col1, col2 = st.columns(2)

with col1:
    st.subheader("üìä R√©sultats de la r√©gression")
    st.write(f"**Pente (b):** {slope:.4f}")
    st.write(f"**Ordonn√©e √† l'origine (a):** {intercept:.4f}")
    st.write(f"**Coefficient de corr√©lation (R):** {r_value:.4f}")
    st.write(f"**R¬≤ (coefficient de d√©termination):** {r_value**2:.4f}")
    st.write(f"**p-value:** {p_value:.4e}")
    st.write(f"**Erreur standard:** {std_err:.4f}")
    
    if r_value**2 > 0.9:
        st.success("‚úÖ Excellente qualit√© d'ajustement (R¬≤ > 0.9)")
    elif r_value**2 > 0.7:
        st.warning("‚ö†Ô∏è Bonne qualit√© d'ajustement (R¬≤ > 0.7)")
    else:
        st.error("‚ùå Qualit√© d'ajustement faible (R¬≤ < 0.7)")

with col2:
    st.subheader("üìê √âquation de la droite de Zipf")
    st.latex(r"\log(T) = a + b \times \log(R)")
    st.write(f"**√âquation:** log(T) = {intercept:.4f} + {slope:.4f} √ó log(R)")
    st.latex(r"T = e^{a} \times R^{b}")
    st.write(f"**Forme exponentielle:** T = {np.exp(intercept):.4f} √ó R^{{{slope:.4f}}}")

# Graphique de Zipf (√©chelle log-log)
st.subheader("üìâ Graphique de Zipf (√©chelle log-log)")

fig1, ax1 = plt.subplots(figsize=(10, 6))
ax1.scatter(df_sorted['Rang'], df_sorted['Tonnage (Mt)'], 
            alpha=0.6, s=100, label='Donn√©es observ√©es', color='steelblue')
ax1.plot(df_sorted['Rang'], df_sorted['Tonnage_pred'], 
         'r--', linewidth=2, label='Droite de Zipf ajust√©e')
ax1.set_xscale('log')
ax1.set_yscale('log')
ax1.set_xlabel('Rang (√©chelle log)', fontsize=12)
ax1.set_ylabel('Tonnage Mt (√©chelle log)', fontsize=12)
ax1.set_title('Loi de Zipf - Distribution des tonnages', fontsize=14, fontweight='bold', loc='center')
ax1.legend()
ax1.grid(True, alpha=0.3)
st.pyplot(fig1)
plt.close()

# Test de Kolmogorov-Smirnov
st.header("üî¨ Test de Kolmogorov-Smirnov")

# Calcul des r√©sidus
residuals = df_sorted['log_Tonnage'] - df_sorted['log_Tonnage_pred']
residuals_standardized = (residuals - residuals.mean()) / residuals.std()

# Test KS pour normalit√©
ks_statistic, ks_pvalue = stats.kstest(residuals_standardized, 'norm')

col1, col2 = st.columns(2)

with col1:
    st.subheader("üìä R√©sultats du test KS")
    st.write(f"**Statistique KS:** {ks_statistic:.4f}")
    st.write(f"**p-value:** {ks_pvalue:.4f}")
    st.write(f"**Niveau de signification (Œ±):** {alpha:.4f}")
    
    if ks_pvalue > alpha:
        st.success(f"‚úÖ Les r√©sidus suivent une distribution normale (p-value = {ks_pvalue:.4f} > Œ± = {alpha:.4f})")
    else:
        st.warning(f"‚ö†Ô∏è Les r√©sidus ne suivent pas une distribution normale (p-value = {ks_pvalue:.4f} ‚â§ Œ± = {alpha:.4f})")

with col2:
    st.subheader("üìà Distribution des r√©sidus")
    fig2, ax2 = plt.subplots(figsize=(8, 6))
    ax2.hist(residuals_standardized, bins=15, density=True, 
             alpha=0.7, color='skyblue', edgecolor='black')
    
    x = np.linspace(residuals_standardized.min(), residuals_standardized.max(), 100)
    ax2.plot(x, stats.norm.pdf(x), 'r-', linewidth=2, label='Distribution normale')
    ax2.set_xlabel('R√©sidus standardis√©s', fontsize=12)
    ax2.set_ylabel('Densit√©', fontsize=12)
    ax2.set_title('Distribution des r√©sidus vs. Normale', fontsize=14, fontweight='bold', loc='center')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    st.pyplot(fig2)
    plt.close()

# Q-Q plot
st.subheader("üìä Q-Q Plot (Quantile-Quantile)")
fig3, ax3 = plt.subplots(figsize=(8, 6))
stats.probplot(residuals_standardized, dist="norm", plot=ax3)
ax3.set_title('Q-Q Plot - V√©rification de la normalit√©', fontsize=14, fontweight='bold', loc='center')
ax3.grid(True, alpha=0.3)
st.pyplot(fig3)
plt.close()

# Pr√©diction des gisements non d√©couverts
st.header("üîÆ Pr√©diction des gisements non d√©couverts")

# Estimation du nombre total de gisements
n_observed = len(df_sorted)
extrapolation_factor = st.slider(
    "Facteur d'extrapolation (% au-del√† du dernier rang observ√©)",
    min_value=10,
    max_value=200,
    value=50,
    step=10
)

n_total_estimated = int(n_observed * (1 + extrapolation_factor / 100))
n_undiscovered = n_total_estimated - n_observed

col1, col2, col3 = st.columns(3)
with col1:
    st.metric("Gisements observ√©s", n_observed)
with col2:
    st.metric("Gisements estim√©s (total)", n_total_estimated)
with col3:
    st.metric("Gisements non d√©couverts", n_undiscovered, delta=f"+{(n_undiscovered/n_observed)*100:.1f}%")

# Pr√©diction des tonnages futurs
future_ranks = np.arange(n_observed + 1, n_total_estimated + 1)
future_log_tonnages = slope * np.log(future_ranks) + intercept
future_tonnages = np.exp(future_log_tonnages)

df_future = pd.DataFrame({
    'Rang': future_ranks,
    'Tonnage_pr√©dit (Mt)': future_tonnages
})

st.subheader("üìã Gisements pr√©dits non d√©couverts")
st.dataframe(df_future.head(20), use_container_width=True)

total_future_tonnage = future_tonnages.sum()
st.info(f"üíé **Tonnage total estim√© des gisements non d√©couverts:** {total_future_tonnage:.2f} Mt")

# Graphique comparatif
st.subheader("üìä Comparaison: Gisements observ√©s vs. Pr√©dits")

fig4 = go.Figure()
fig4.add_trace(go.Scatter(
    x=df_sorted['Rang'],
    y=df_sorted['Tonnage (Mt)'],
    mode='markers',
    name='Gisements observ√©s',
    marker=dict(size=10, color='steelblue')
))
fig4.add_trace(go.Scatter(
    x=df_future['Rang'],
    y=df_future['Tonnage_pr√©dit (Mt)'],
    mode='markers',
    name='Gisements pr√©dits',
    marker=dict(size=8, color='coral', symbol='diamond')
))
fig4.update_xaxes(type="log", title="Rang (√©chelle log)")
fig4.update_yaxes(type="log", title="Tonnage Mt (√©chelle log)")
fig4.update_layout(
    title={
        'text': "Distribution compl√®te: Observ√©s + Pr√©dictions",
        'x': 0.5,
        'xanchor': 'center'
    },
    height=500,
    hovermode='closest'
)
st.plotly_chart(fig4, use_container_width=True)

# Analyse de sensibilit√©
st.header("üéØ Analyse de sensibilit√©")

st.write("Impact du facteur d'extrapolation sur les estimations:")

sensitivity_factors = [10, 25, 50, 75, 100, 150, 200]
sensitivity_results = []

for factor in sensitivity_factors:
    n_total = int(n_observed * (1 + factor / 100))
    n_undiscov = n_total - n_observed
    future_r = np.arange(n_observed + 1, n_total + 1)
    future_t = np.exp(slope * np.log(future_r) + intercept)
    total_t = future_t.sum()
    
    sensitivity_results.append({
        'Facteur (%)': factor,
        'Gisements totaux': n_total,
        'Gisements non d√©couverts': n_undiscov,
        'Tonnage pr√©dit (Mt)': total_t
    })

df_sensitivity = pd.DataFrame(sensitivity_results)
st.dataframe(df_sensitivity, use_container_width=True)

# Graphique de sensibilit√©
fig5, (ax5a, ax5b) = plt.subplots(1, 2, figsize=(14, 5))

ax5a.plot(df_sensitivity['Facteur (%)'], df_sensitivity['Gisements non d√©couverts'], 
          marker='o', linewidth=2, color='steelblue')
ax5a.set_xlabel('Facteur d\'extrapolation (%)', fontsize=12)
ax5a.set_ylabel('Nombre de gisements non d√©couverts', fontsize=12)
ax5a.set_title('Impact sur le nombre de gisements', fontsize=14, fontweight='bold', loc='center')
ax5a.grid(True, alpha=0.3)

ax5b.plot(df_sensitivity['Facteur (%)'], df_sensitivity['Tonnage pr√©dit (Mt)'], 
          marker='s', linewidth=2, color='coral')
ax5b.set_xlabel('Facteur d\'extrapolation (%)', fontsize=12)
ax5b.set_ylabel('Tonnage total pr√©dit (Mt)', fontsize=12)
ax5b.set_title('Impact sur le tonnage total', fontsize=14, fontweight='bold', loc='center')
ax5b.grid(True, alpha=0.3)

plt.tight_layout()
st.pyplot(fig5)
plt.close()

# Statistiques suppl√©mentaires
st.header("üìä Statistiques suppl√©mentaires")

col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("üìà Tonnages observ√©s")
    st.write(f"**Minimum:** {df_sorted['Tonnage (Mt)'].min():.2f} Mt")
    st.write(f"**Maximum:** {df_sorted['Tonnage (Mt)'].max():.2f} Mt")
    st.write(f"**M√©diane:** {df_sorted['Tonnage (Mt)'].median():.2f} Mt")
    st.write(f"**√âcart-type:** {df_sorted['Tonnage (Mt)'].std():.2f} Mt")

with col2:
    st.subheader("üîÆ Tonnages pr√©dits")
    st.write(f"**Minimum:** {df_future['Tonnage_pr√©dit (Mt)'].min():.2f} Mt")
    st.write(f"**Maximum:** {df_future['Tonnage_pr√©dit (Mt)'].max():.2f} Mt")
    st.write(f"**M√©diane:** {df_future['Tonnage_pr√©dit (Mt)'].median():.2f} Mt")
    st.write(f"**√âcart-type:** {df_future['Tonnage_pr√©dit (Mt)'].std():.2f} Mt")

with col3:
    st.subheader("üí∞ Totaux cumul√©s")
    st.write(f"**Tonnage observ√©:** {df_sorted['Tonnage (Mt)'].sum():.2f} Mt")
    st.write(f"**Tonnage pr√©dit:** {total_future_tonnage:.2f} Mt")
    st.write(f"**Total combin√©:** {df_sorted['Tonnage (Mt)'].sum() + total_future_tonnage:.2f} Mt")
    percentage_increase = (total_future_tonnage / df_sorted['Tonnage (Mt)'].sum()) * 100
    st.write(f"**Augmentation:** +{percentage_increase:.1f}%")

# Export des r√©sultats
st.header("üíæ Export des r√©sultats")

col1, col2, col3 = st.columns(3)

with col1:
    # Export des donn√©es observ√©es
    csv_observed = df_sorted.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• T√©l√©charger les donn√©es observ√©es (CSV)",
        data=csv_observed,
        file_name="donnees_observees.csv",
        mime="text/csv"
    )

with col2:
    # Export des pr√©dictions
    csv_predictions = df_future.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• T√©l√©charger les pr√©dictions (CSV)",
        data=csv_predictions,
        file_name="predictions_gisements.csv",
        mime="text/csv"
    )

with col3:
    # Export de l'analyse de sensibilit√©
    csv_sensitivity = df_sensitivity.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• T√©l√©charger l'analyse de sensibilit√© (CSV)",
        data=csv_sensitivity,
        file_name="analyse_sensibilite.csv",
        mime="text/csv"
    )

# Documentation et m√©thodologie
with st.expander("üìñ Documentation et M√©thodologie"):
    st.markdown("""
    ## M√©thodologie de l'Analyse de Zipf
    
    ### 1. Loi de Zipf
    La loi de Zipf, appliqu√©e aux gisements min√©raux, stipule que le tonnage d'un gisement est inversement proportionnel √† son rang:
    
    **T = C √ó R^(-b)**
    
    O√π:
    - T = Tonnage du gisement
    - R = Rang du gisement (du plus grand au plus petit)
    - C = Constante
    - b = Exposant de Zipf (g√©n√©ralement proche de 1)
    
    ### 2. Transformation logarithmique
    En appliquant le logarithme naturel, on obtient une relation lin√©aire:
    
    **log(T) = a + b √ó log(R)**
    
    ### 3. R√©gression lin√©aire
    La r√©gression lin√©aire permet d'estimer les param√®tres a et b, ainsi que la qualit√© de l'ajustement (R¬≤).
    
    ### 4. Test de Kolmogorov-Smirnov
    Ce test v√©rifie si les r√©sidus suivent une distribution normale, validant ainsi le mod√®le statistique.
    
    ### 5. Pr√©dictions
    Le mod√®le calibr√© permet d'extrapoler et d'estimer le nombre et le tonnage des gisements non encore d√©couverts.
    
    ### Limites et pr√©cautions
    - Les pr√©dictions d√©pendent de la qualit√© des donn√©es d'entr√©e
    - Le facteur d'extrapolation doit √™tre choisi judicieusement
    - Les r√©sultats doivent √™tre interpr√©t√©s dans le contexte g√©ologique de la province
    """)

# Pied de page
st.markdown("""
    <div class="footer">
        <p><strong>D√©velopp√© par Didier Ouedraogo, P.Geo | Koulou Danshoko, Geo</strong></p>
    </div>
    """, unsafe_allow_html=True)